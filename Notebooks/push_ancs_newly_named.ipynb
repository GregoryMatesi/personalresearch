{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Solving Many Ancestries problem, multiple SNPs\n",
    "\n",
    "In this notebook we attempt to solve the following constrained, quadratic optimization problem:\n",
    "\n",
    "$$\\min_{\\pi \\in \\mathbb{R}^k} f(\\pi)=\\sum_{i=1}^{N}\\left(\\sum_{j=1}^k a_{j,i}\\pi_j-\\tilde{a}_i\\right)^2$$\n",
    "\n",
    "$$\\text{subject to:} \\sum_{j=1}^k \\pi_k=1 \\quad \\pi_j \\geq 0, j=1,\\ldots,k,$$\n",
    "\n",
    "where $a_{j,i} \\in \\mathbb{R}$, $j=1,\\ldots, k$; $i=1,\\ldots N$ and $\\tilde{a}_i \\in \\mathbb{R}$, $i =1, \\ldots, N$ are quantities obtained from a genetics simulation. The $a_{j,i}$'s correspond to the observed allele frequency in ancestry $j$ at SNP $i$. There are $k$ ancestries and $N$ SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 15) (50000, 1) (15, 1) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "N=50000 # number of SNPs\n",
    "k=15 # number of ancestries\n",
    "\n",
    "A=np.array(np.random.uniform(low=0, high=1, size=(N,1))) # initialize an array for experimental draws\n",
    "\n",
    "for i in range(1,k):\n",
    "    A=np.hstack((A,np.random.uniform(low=0, high=1, size=(N,1))))\n",
    "\n",
    "# First, we choose an answer! This vector must be Nx1\n",
    "\n",
    "ans=[[0.1], [0.15], [0.2], [0.25], [0], [0.05], [0.02], [0.01], [0.005], [0], [0], [0.1], [0.1], [0], [0.005]]\n",
    "\n",
    "taf=A@ans # Total allele frequency\n",
    "\n",
    "print(np.shape(A),np.shape(taf), np.shape(ans), np.shape(taf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the objective function!\n",
    "\n",
    "def gen_function(x):\n",
    "    b=0\n",
    "    for i in range(0,k):\n",
    "        b=b + x[i]*A[:,i:(i+1)]\n",
    "    b=b-taf\n",
    "    return np.sum(b**2, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check shape of x_t: (15, 1) [1.]\n",
      "our initial value is [[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      "  0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      "  0.06666667 0.06666667 0.06666667]]\n",
      "which has function value 388.3046892151477\n"
     ]
    }
   ],
   "source": [
    "# This is a feasible initial point since its components add to 1 and are positive.\n",
    "\n",
    "x_t=(1/k)*np.ones((k,1))\n",
    "print('check shape of x_t:', np.shape(x_t), np.sum(x_t,axis=0))\n",
    "\n",
    "# Make sure function works by computing f(x_t)\n",
    "\n",
    "print('our initial value is', np.transpose(x_t)) # transpose for readability only\n",
    "print('which has function value', gen_function(x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the gradient of the objective function\n",
    "\n",
    "def gen_gradfun(x):\n",
    "    \n",
    "    gradvec = np.zeros((k,1))\n",
    "    \n",
    "    d=0\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        d=d + x[i]*A[:,i:(i+1)]\n",
    "    d=d-taf\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        gradvec[i,:] = np.sum(2*A[:,i:(i+1)]*d, axis=0)\n",
    "    return gradvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad of starting point is: [[  -43.20603307  -467.47809344  -896.14193183 -1297.58718218\n",
      "    789.54989447   369.59392999   626.05759405   697.61840904\n",
      "    732.46131016   779.41366605   780.6834401    -47.63155617\n",
      "    -70.47316651   780.41055318   748.42200588]]\n",
      "should be zeros: [[-2.82064426e-14 -3.40915396e-14 -4.59081626e-14 -5.51547318e-14\n",
      "  -3.84164998e-14 -2.25130846e-14 -2.74672093e-14 -2.49143585e-14\n",
      "  -1.35277338e-14 -2.43695337e-14 -1.46814036e-14 -5.22985240e-15\n",
      "  -1.32070448e-14 -2.57220122e-14 -2.72564919e-15]]\n"
     ]
    }
   ],
   "source": [
    "s=gen_gradfun(x_t)\n",
    "zero=gen_gradfun(ans)\n",
    "\n",
    "print('grad of starting point is:',np.transpose(s)) # this is the gradient of where we begin\n",
    "print('should be zeros:',np.transpose(zero)) # this should be zero if we have the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are wrappers that make our constraints and our bounds\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x,axis=0) -1},)\n",
    "\n",
    "for i in range(0,k-1):\n",
    "    cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]},)\n",
    "\n",
    "bnds = ((0, None),)\n",
    "\n",
    "for i in range(0,k-1):\n",
    "    bnds = bnds + ((0, None),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 1.2760067618512503\n",
      "     jac: array([254.6406695 , 255.16149974, 255.30448387, 254.83016562,\n",
      "       255.81706791, 254.99902426, 254.91936865, 254.78982926,\n",
      "       254.96373357, 255.67967757, 255.44170472, 255.04227613,\n",
      "       255.04867348, 256.00006087, 254.85080864])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 68\n",
      "     nit: 29\n",
      "    njev: 29\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.10071637, 0.15068574, 0.20064008, 0.25051084, 0.00070234,\n",
      "       0.05056845, 0.02069921, 0.01067863, 0.00557056, 0.00072031,\n",
      "       0.00078654, 0.1005591 , 0.10068855, 0.00088922, 0.00558407])\n",
      "Time:  1.2299670490710923\n",
      "our correct answer was chosen to be [[0.1], [0.15], [0.2], [0.25], [0], [0.05], [0.02], [0.01], [0.005], [0], [0], [0.1], [0.1], [0], [0.005]]\n"
     ]
    }
   ],
   "source": [
    "# This cell runs and times SLSQP\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "print(scipy.optimize.minimize(gen_function, x_t, method='SLSQP', jac=gen_gradfun, bounds=bnds, constraints=cons, tol=1e-5))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "print('our correct answer was chosen to be', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we call the computed answer, x, without copy/pasting?!\n",
    "\n",
    "x=np.array([0.10071637, 0.15068574, 0.20064008, 0.25051084, 0.00070234,\n",
    "       0.05056845, 0.02069921, 0.01067863, 0.00557056, 0.00072031,\n",
    "       0.00078654, 0.1005591 , 0.10068855, 0.00088922, 0.00558407])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00088922"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the error in the worst component\n",
    "\n",
    "np.max(abs(x-np.transpose(ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.77579999999996e-05"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out average error\n",
    "\n",
    "(1/k)*np.sum(abs(x-np.transpose(ans)),axis=0)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
